{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6dc024b-4c68-4042-ba30-bf116c67da14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Big Data Analytics Project - Airbnb Pricing Prediction <br>\n",
    "\n",
    "### Group 63 <br>\n",
    "André Lourenço - 20240743 <br>\n",
    "Fábio Dos Santos - 20240678 <br>\n",
    "Rafael Borges - 20240497 <br>\n",
    "Rui Reis - 20240854 <br>\n",
    "Victor Silva - 20240663 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1144e838-8822-4b35-86cf-e60ef0be83c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Table of Contents\n",
    "- [1. Import Libraries](#1-import-libraries)\n",
    "- [2. Data Load](#2-data-load)\n",
    "- [3. Pipeline](#3-pipeline)\n",
    "- [4. Model Evaluation](#4-model-evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e39b38c2-380b-416a-b533-2fda9d615c14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48a2887d-313e-462a-872f-c75f5e365c8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "__`Step 1`__ Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9021d181-9636-4741-9627-8dab513aa711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, year, to_date, avg, regexp_replace, current_date, datediff, countDistinct, sum, round, when, lit\n",
    "from pyspark.sql import functions as F\n",
    "from functools import reduce\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler,\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    Imputer,\n",
    "    RobustScaler\n",
    ")\n",
    "from pyspark.ml.regression import RandomForestRegressor, LinearRegression, GBTRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.param.shared import Param\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4915c785-e42c-4015-b3fe-58620e7c6f4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "__`Step 2`__ Run both utils and transformers notebooks used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddc40bc4-0bba-4e81-aaa1-6b9e03c22ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run \"./utils\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20ef326a-05e1-4fba-9d59-3d2776c2a434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./transformers\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "694edebe-a0ce-42e8-a0fd-b0c6b00d2ebe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0abedda9-1680-47f5-8e24-7f077a50e4a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "__`Step 3`__ Import the initially preprocessed data from the EDA notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3229c279-06fb-4164-a3d0-0591805c6830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>host_is_superhost</th><th>host_total_listings_count</th><th>host_has_profile_pic</th><th>host_identity_verified</th><th>neighbourhood</th><th>property_type</th><th>room_type</th><th>accommodates</th><th>bedrooms</th><th>price</th><th>minimum_nights</th><th>review_scores_rating</th><th>instant_bookable</th><th>host_days_active</th><th>host_years_active</th><th>amenities_length</th><th>living_entertainment</th><th>kitchen_dining</th><th>bedroom</th><th>bathroom</th><th>baby_family</th><th>laundry_cleaning</th><th>safety_security</th><th>outdoor_garden</th><th>heating_cooling</th><th>travel_access</th><th>wellness_leisure</th><th>workspace_tech</th><th>guest_services</th><th>misc_essentials</th></tr></thead><tbody><tr><td>0</td><td>1</td><td>1</td><td>0</td><td>Buttes-Montmartre</td><td>entire_place</td><td>Entire place</td><td>2</td><td>1</td><td>53</td><td>2</td><td>100</td><td>0</td><td>3354</td><td>9</td><td>5</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td><td>1</td><td>Buttes-Montmartre</td><td>entire_place</td><td>Entire place</td><td>2</td><td>1</td><td>120</td><td>2</td><td>100</td><td>0</td><td>2627</td><td>7</td><td>8</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td></tr><tr><td>0</td><td>1</td><td>1</td><td>0</td><td>Elysee</td><td>entire_place</td><td>Entire place</td><td>2</td><td>1</td><td>89</td><td>2</td><td>100</td><td>0</td><td>2383</td><td>6</td><td>6</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td><td>1</td><td>Vaugirard</td><td>entire_place</td><td>Entire place</td><td>2</td><td>1</td><td>58</td><td>2</td><td>100</td><td>0</td><td>2609</td><td>7</td><td>5</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td><td>0</td><td>Passy</td><td>entire_place</td><td>Entire place</td><td>2</td><td>1</td><td>60</td><td>2</td><td>100</td><td>0</td><td>2247</td><td>6</td><td>12</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         1,
         1,
         0,
         "Buttes-Montmartre",
         "entire_place",
         "Entire place",
         2,
         1,
         53,
         2,
         100,
         0,
         3354,
         9,
         5,
         0,
         1,
         0,
         0,
         0,
         1,
         0,
         0,
         1,
         1,
         0,
         1,
         0,
         0
        ],
        [
         0,
         1,
         1,
         1,
         "Buttes-Montmartre",
         "entire_place",
         "Entire place",
         2,
         1,
         120,
         2,
         100,
         0,
         2627,
         7,
         8,
         0,
         1,
         0,
         1,
         0,
         2,
         0,
         0,
         1,
         1,
         0,
         1,
         0,
         1
        ],
        [
         0,
         1,
         1,
         0,
         "Elysee",
         "entire_place",
         "Entire place",
         2,
         1,
         89,
         2,
         100,
         0,
         2383,
         6,
         6,
         1,
         1,
         0,
         0,
         0,
         1,
         0,
         0,
         1,
         1,
         0,
         1,
         0,
         0
        ],
        [
         0,
         1,
         1,
         1,
         "Vaugirard",
         "entire_place",
         "Entire place",
         2,
         1,
         58,
         2,
         100,
         0,
         2609,
         7,
         5,
         1,
         1,
         0,
         0,
         0,
         0,
         0,
         0,
         1,
         1,
         0,
         1,
         0,
         0
        ],
        [
         0,
         1,
         1,
         0,
         "Passy",
         "entire_place",
         "Entire place",
         2,
         1,
         60,
         2,
         100,
         0,
         2247,
         6,
         12,
         1,
         1,
         0,
         1,
         0,
         2,
         0,
         0,
         1,
         1,
         0,
         1,
         0,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "host_is_superhost",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "host_total_listings_count",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "host_has_profile_pic",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "host_identity_verified",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "neighbourhood",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "property_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "room_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "accommodates",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bedrooms",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "minimum_nights",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "review_scores_rating",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "instant_bookable",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "host_days_active",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "host_years_active",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "amenities_length",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "living_entertainment",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "kitchen_dining",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bedroom",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bathroom",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "baby_family",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "laundry_cleaning",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "safety_security",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "outdoor_garden",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "heating_cooling",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "travel_access",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "wellness_leisure",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "workspace_tech",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "guest_services",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "misc_essentials",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")      # keep column names\n",
    "         .option(\"inferSchema\", \"true\") # let Spark inspect values & choose types\n",
    "         .option(\"samplingRatio\", \"1\")  \n",
    "         .csv(\"dbfs:/FileStore/tables/Listings_cleaned\")\n",
    ")\n",
    "\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13c02d94-bc8a-433b-97d3-2eaf00952ce8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63750 rows × 30 columns\n"
     ]
    }
   ],
   "source": [
    "df_shape(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c796660e-1bd7-4f53-80e5-1a8d77c4d9e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "__`Step 4`__ Check for null values and respective data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "272c9b68-7fb1-450a-b53e-cb1de56ef752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column                         |    # nulls | dtype\n---------------------------------------------------\nbedrooms                       |     13,293 | int\nreview_scores_rating           |     16,199 | int\n"
     ]
    }
   ],
   "source": [
    "summarize_nulls_and_dtype(df, only_missing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ef5f4f5-d672-44e7-bc3b-f79941fc9d47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3. Pipeline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e01f440f-cf0e-4527-87ba-6b603cb4873a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- host_is_superhost: integer (nullable = true)\n |-- host_total_listings_count: integer (nullable = true)\n |-- host_has_profile_pic: integer (nullable = true)\n |-- host_identity_verified: integer (nullable = true)\n |-- neighbourhood: string (nullable = true)\n |-- property_type: string (nullable = true)\n |-- room_type: string (nullable = true)\n |-- accommodates: integer (nullable = true)\n |-- bedrooms: integer (nullable = true)\n |-- price: integer (nullable = true)\n |-- minimum_nights: integer (nullable = true)\n |-- review_scores_rating: integer (nullable = true)\n |-- instant_bookable: integer (nullable = true)\n |-- host_days_active: integer (nullable = true)\n |-- host_years_active: integer (nullable = true)\n |-- amenities_length: integer (nullable = true)\n |-- living_entertainment: integer (nullable = true)\n |-- kitchen_dining: integer (nullable = true)\n |-- bedroom: integer (nullable = true)\n |-- bathroom: integer (nullable = true)\n |-- baby_family: integer (nullable = true)\n |-- laundry_cleaning: integer (nullable = true)\n |-- safety_security: integer (nullable = true)\n |-- outdoor_garden: integer (nullable = true)\n |-- heating_cooling: integer (nullable = true)\n |-- travel_access: integer (nullable = true)\n |-- wellness_leisure: integer (nullable = true)\n |-- workspace_tech: integer (nullable = true)\n |-- guest_services: integer (nullable = true)\n |-- misc_essentials: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71312dad-c74d-4123-8dd1-cf38c2771a45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    'property_type', \n",
    "    'room_type', \n",
    "    'neighbourhood',\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    'host_total_listings_count',\n",
    "    'accommodates', \n",
    "    'bedrooms', \n",
    "    'minimum_nights', \n",
    "    'review_scores_rating', \n",
    "    'host_days_active',\n",
    "    'host_years_active',\n",
    "    'amenities_length', \n",
    "    \"living_entertainment\", \n",
    "    \"kitchen_dining\", \n",
    "    \"bedroom\", \n",
    "    \"bathroom\", \n",
    "    \"baby_family\", \n",
    "    \"laundry_cleaning\", \n",
    "    \"safety_security\", \n",
    "    \"outdoor_garden\", \n",
    "    \"heating_cooling\", \n",
    "    \"travel_access\", \n",
    "    \"wellness_leisure\", \n",
    "    \"workspace_tech\", \n",
    "    \"guest_services\", \n",
    "    \"misc_essentials\",\n",
    "]\n",
    "\n",
    "binary_cols = [\n",
    "    \"host_is_superhost\",\n",
    "    \"host_has_profile_pic\",\n",
    "    \"host_identity_verified\",\n",
    "    \"instant_bookable\"\n",
    "]\n",
    "\n",
    "label_col = \"price\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ec8fc17-78cd-492d-9b20-187d017c6ed2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "__`Step 5`__ Create and run the pipeline to explore the models and their parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bb7fd7e-906a-4a1a-85dc-c7881ef3f41e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## RANDOM FOREST REGRESSOR PIPELINE\n",
    "\n",
    "# 1. Train/test split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 2. Build pipeline stages (applied per CV fold)\n",
    "stages = []\n",
    "\n",
    "# 2a. Categorical processing\n",
    "for cat in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=cat, outputCol=f\"{cat}_idx\")\n",
    "    ohe = OneHotEncoder(inputCol=f\"{cat}_idx\", outputCol=f\"{cat}_ohe\")\n",
    "    stages += [indexer, ohe]\n",
    "\n",
    "# 2b. Numeric imputation\n",
    "current_numeric_cols = list(numeric_cols) # Make a copy to modify\n",
    "processed_cols_map = {col: col for col in numeric_cols}\n",
    "\n",
    "\n",
    "imputer_input_actual = [\"review_scores_rating\", \"bedrooms\"] \n",
    "imputer_output_actual = [f\"{c}_imputed\" for c in imputer_input_actual]\n",
    "imputer = Imputer(inputCols=imputer_input_actual, outputCols=imputer_output_actual).setStrategy(\"median\")\n",
    "stages.append(imputer)\n",
    "\n",
    "# Update dict\n",
    "for orig_col, imputed_col in zip(imputer_input_actual, imputer_output_actual):\n",
    "    processed_cols_map[orig_col] = imputed_col\n",
    "\n",
    "# 2c. Winsorization\n",
    "\n",
    "winsor_input_original_names = [\"bedrooms\", \"minimum_nights\"] # Original names\n",
    "winsor_input_current_names = [processed_cols_map[c] for c in winsor_input_original_names]\n",
    "winsor_output = [f\"{processed_cols_map[c]}_wins\" for c in winsor_input_original_names]\n",
    "\n",
    "winsor = Winsorizer(\n",
    "    inputCols=winsor_input_current_names,\n",
    "    outputCols=winsor_output,\n",
    "    lowerQuantile=0.05,\n",
    "    upperQuantile=0.95\n",
    ")\n",
    "stages.append(winsor)\n",
    "\n",
    "\n",
    "# Update dict \n",
    "for orig_col, wins_col in zip(winsor_input_original_names, winsor_output):\n",
    "    processed_cols_map[orig_col] = wins_col\n",
    "\n",
    "final_numeric_features = list(processed_cols_map.values())\n",
    "\n",
    "# 2d. Assemble features\n",
    "onehot_cols  = [f\"{c}_ohe\" for c in categorical_cols]\n",
    "\n",
    "\n",
    "# Final feature input list\n",
    "feature_inputs = final_numeric_features + onehot_cols + binary_cols\n",
    "assembler = VectorAssembler(inputCols=feature_inputs, outputCol=\"assembled_features\")\n",
    "stages.append(assembler)\n",
    "\n",
    "# 3. Estimator: RandomForestRegressor (or swap LinearRegression)\n",
    "regressor = RandomForestRegressor(featuresCol=\"assembled_features\", labelCol=label_col, seed=42)\n",
    "stages.append(regressor)\n",
    "\n",
    "# 4. Pipeline creation\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e69254dd-1d52-4032-97de-1a49453b829a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First Run:\n",
    "- Model: Random Forest Regressor.\n",
    "- Parameters: numTrees -> [20, 50]; maxDepth -> [5, 10].\n",
    "- Number of folds: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11704e6c-e5a4-4344-bda1-a57bcb6b2b7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best numTrees: 50\nBest maxDepth: 10\nTest RMSE = 49.3855, R2 = 0.4997\n"
     ]
    }
   ],
   "source": [
    "# 5. Hyperparameter grid for Random Forest\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.numTrees, [20, 50]) \\\n",
    "    .addGrid(regressor.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "# 6. Cross-validation setup\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=2,\n",
    "    seed = 42 \n",
    ")\n",
    "\n",
    "# 7. Model fitting\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# 8. Best model & params\n",
    "best_model = cv_model.bestModel\n",
    "best_rf = best_model.stages[-1]\n",
    "print(f\"Best numTrees: {best_rf.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf.getOrDefault('maxDepth')}\")\n",
    "\n",
    "# 9. Test set evaluation\n",
    "preds = best_model.transform(test_df)\n",
    "rmse = evaluator.evaluate(preds)\n",
    "r2 = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\").evaluate(preds)\n",
    "print(f\"Test RMSE = {rmse:.4f}, R2 = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "834f7717-4364-4dd8-9309-280685d197bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Results: <br>\n",
    "- Best number of trees: 50\n",
    "- Best max depth: 10\n",
    "- Test RMSE: 49.3855\n",
    "- R2: 0.4997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5ce31af0-017b-41aa-8501-8898c401c5fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Second Run:\n",
    "- Model: Random Forest Regressor.\n",
    "- Parameters: minInstancesPerNode -> [1, 5]; numTrees -> [10, 20, 50, 100]; maxDepth -> [3, 5].\n",
    "- Number of folds: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e691d48-3e66-44fe-af50-d99a8cf26560",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best numTrees: 100\nBest maxDepth: 5\nTest RMSE = 52.4792, R2 = 0.4351\n"
     ]
    }
   ],
   "source": [
    "# 5. Hyperparameter grid for Random Forest\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.minInstancesPerNode, [1, 5]) \\\n",
    "    .addGrid(regressor.numTrees, [10, 20, 50, 100]) \\\n",
    "    .addGrid(regressor.maxDepth, [3, 5]) \\\n",
    "    .build()\n",
    "\n",
    "\n",
    "# 6. Cross-validation setup\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=4,\n",
    "    parallelism=2,\n",
    "    seed = 42 \n",
    ")\n",
    "\n",
    "# 7. Model fitting\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# 8. Best model & params\n",
    "best_model = cv_model.bestModel\n",
    "best_rf = best_model.stages[-1]\n",
    "print(f\"Best numTrees: {best_rf.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf.getOrDefault('maxDepth')}\")\n",
    "\n",
    "# 9. Test set evaluation\n",
    "preds = best_model.transform(test_df)\n",
    "rmse = evaluator.evaluate(preds)\n",
    "r2 = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\").evaluate(preds)\n",
    "print(f\"Test RMSE = {rmse:.4f}, R2 = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc560210-f4bd-4fbb-af1b-386623ccd087",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Results: <br>\n",
    "- Best number of trees: 100\n",
    "- Best max depth: 5\n",
    "- Test RMSE: 52.4792\n",
    "- R2: 0.4531"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7ede30ac-0929-42c9-902c-8e1a97e5883f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Third Run:\n",
    "- Model: Random Forest Regressor.\n",
    "- Parameters: minInstancesPerNode -> [1, 5]; numTrees -> [10, 20, 50, 100]; maxDepth -> [5, 10].\n",
    "- Number of folds: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60bbabc4-729b-4d0c-9256-769894511b44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best numTrees: 100\nBest maxDepth: 10\nTest RMSE = 49.3130, R2 = 0.5012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Hyperparameter grid for Random Forest\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.minInstancesPerNode, [1, 5]) \\\n",
    "    .addGrid(regressor.numTrees, [10, 20, 50, 100]) \\\n",
    "    .addGrid(regressor.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "# 6. Cross-validation setup\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5,\n",
    "    parallelism=2,\n",
    "    seed = 42 \n",
    ")\n",
    "\n",
    "# 7. Model fitting\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# 8. Best model & params\n",
    "best_model = cv_model.bestModel\n",
    "best_rf = best_model.stages[-1]\n",
    "print(f\"Best numTrees: {best_rf.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf.getOrDefault('maxDepth')}\")\n",
    "\n",
    "# 9. Test set evaluation\n",
    "preds = best_model.transform(test_df)\n",
    "rmse = evaluator.evaluate(preds)\n",
    "r2 = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\").evaluate(preds)\n",
    "print(f\"Test RMSE = {rmse:.4f}, R2 = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "512f77b6-5d68-442a-8229-016d59ecb273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Results: <br>\n",
    "- Best number of trees: 100\n",
    "- Best max depth: 10\n",
    "- Test RMSE: 49.3130\n",
    "- R2: 0.5012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df963323-8b95-48ff-b9d6-9e64f3375465",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Fourth Run:\n",
    "- Model: Random Forest Regressor.\n",
    "- Parameters: numTrees -> [100, 125]; maxDepth -> [12, 15].\n",
    "- Number of folds: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d80ca110-a8c3-4277-901c-a4d614a8aef8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best numTrees: 125\nBest maxDepth: 15\nTest RMSE = 47.5310, R2 = 0.5366\n"
     ]
    }
   ],
   "source": [
    "# 5. Hyperparameter grid for Random Forest\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.numTrees, [100, 125]) \\\n",
    "    .addGrid(regressor.maxDepth, [12, 15]) \\\n",
    "    .build()\n",
    "\n",
    "# 6. Cross-validation setup\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=2,\n",
    "    seed = 42 \n",
    ")\n",
    "\n",
    "# 7. Model fitting\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# 8. Best model & params\n",
    "best_model = cv_model.bestModel\n",
    "best_rf = best_model.stages[-1]\n",
    "print(f\"Best numTrees: {best_rf.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf.getOrDefault('maxDepth')}\")\n",
    "\n",
    "# 9. Test set evaluation\n",
    "preds = best_model.transform(test_df)\n",
    "rmse = evaluator.evaluate(preds)\n",
    "r2 = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\").evaluate(preds)\n",
    "print(f\"Test RMSE = {rmse:.4f}, R2 = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d12c289-0c13-4180-bbe5-2733fb37f04c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Results: <br>\n",
    "- Best number of trees: 125\n",
    "- Best max depth: 15\n",
    "- Test RMSE: 47.5310\n",
    "- R2: 0.5366"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d97160f5-99f6-40d2-85ea-408c725eeadb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next we have one of the five examples of pipeline setups using Random Forest Regressor that didn't finish running due to Databricks Community Edition limitations, after 1 hour of running the same code cell the cluster goes down and interrupts the run showing \"Cancelled\" as output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4ce3162-82d3-4159-9720-48e5599b867b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Command skipped",
       "errorTraceType": "html",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Hyperparameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.minInstancesPerNode, [1, 5]) \\\n",
    "    .addGrid(regressor.minInfoGain, [0.0, 0.01]) \\\n",
    "    .addGrid(regressor.numTrees, [10, 20, 50, 100]) \\\n",
    "    .addGrid(regressor.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "\n",
    "# 6. Cross-validation setup\n",
    "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "# 7. Model fitting\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# 8. Best model & params\n",
    "best_model = cv_model.bestModel\n",
    "best_rf = best_model.stages[-1]\n",
    "print(f\"Best numTrees: {best_rf.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf.getOrDefault('maxDepth')}\")\n",
    "\n",
    "# 9. Test set evaluation\n",
    "preds = best_model.transform(test_df)\n",
    "rmse = evaluator.evaluate(preds)\n",
    "r2 = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"r2\").evaluate(preds)\n",
    "print(f\"Test RMSE = {rmse:.4f}, R2 = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4f602b4-2d40-4d11-a7e4-ba5a191392ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A solution to turn around this problem would be to run this pipeline in smaller batches but we didn't wanted to loose information, therefore we opted not to have that approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31b0b0bd-9c07-4984-9ab8-d0f52db0ce87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "__`Step 6`__ Adapt pipeline to use Gradient Boosting Trees as regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85cd3a1c-ddfb-4767-93e6-064f3d796d65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Train/test split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 5. Build pipeline stages (applied per CV fold)\n",
    "stages = []\n",
    "\n",
    "# 5a. Categorical processing\n",
    "for cat in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=cat, outputCol=f\"{cat}_idx\")\n",
    "    ohe = OneHotEncoder(inputCol=f\"{cat}_idx\", outputCol=f\"{cat}_ohe\")\n",
    "    stages += [indexer, ohe]\n",
    "\n",
    "# 5b. Numeric imputation\n",
    "current_numeric_cols = list(numeric_cols) # Make a copy to modify\n",
    "processed_cols_map = {col: col for col in numeric_cols}\n",
    "\n",
    "\n",
    "imputer_input_actual = [\"review_scores_rating\", \"bedrooms\"] \n",
    "imputer_output_actual = [f\"{c}_imputed\" for c in imputer_input_actual]\n",
    "imputer = Imputer(inputCols=imputer_input_actual, outputCols=imputer_output_actual).setStrategy(\"median\")\n",
    "stages.append(imputer)\n",
    "\n",
    "# Update dict\n",
    "for orig_col, imputed_col in zip(imputer_input_actual, imputer_output_actual):\n",
    "    processed_cols_map[orig_col] = imputed_col\n",
    "\n",
    "# 5c. Winsorization\n",
    "\n",
    "winsor_input_original_names = [\"bedrooms\", \"minimum_nights\"] # Original names\n",
    "winsor_input_current_names = [processed_cols_map[c] for c in winsor_input_original_names]\n",
    "winsor_output = [f\"{processed_cols_map[c]}_wins\" for c in winsor_input_original_names]\n",
    "\n",
    "winsor = Winsorizer(\n",
    "    inputCols=winsor_input_current_names,\n",
    "    outputCols=winsor_output,\n",
    "    lowerQuantile=0.05,\n",
    "    upperQuantile=0.95\n",
    ")\n",
    "stages.append(winsor)\n",
    "\n",
    "# Update dict \n",
    "for orig_col, wins_col in zip(winsor_input_original_names, winsor_output):\n",
    "    processed_cols_map[orig_col] = wins_col\n",
    "\n",
    "final_numeric_features = list(processed_cols_map.values())\n",
    "\n",
    "# 5e. Assemble features\n",
    "onehot_cols  = [f\"{c}_ohe\" for c in categorical_cols]\n",
    "\n",
    "# Final feature input list\n",
    "feature_inputs = final_numeric_features + onehot_cols + binary_cols\n",
    "assembler = VectorAssembler(inputCols=feature_inputs, outputCol=\"assembled_features\")\n",
    "stages.append(assembler)\n",
    "\n",
    "# 5f. Feature scaling ( Unnecessary for tree based models )\n",
    "#scaler = RobustScaler(inputCol=\"assembled_features\", outputCol=\"features\")\n",
    "#stages.append(scaler)\n",
    "\n",
    "regressor =  GBTRegressor(featuresCol=\"assembled_features\", labelCol=label_col, seed=42)\n",
    "stages.append(regressor)\n",
    "\n",
    "# 7. Pipeline creation\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30fbce85-8491-4df8-8358-bb237ba1291e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Fifth Run:\n",
    "- Model: GBT Regressor.\n",
    "- Parameters: maxIter -> [20, 50]; maxDepth -> [3, 5]; stepSize -> [0.1, 0.05].\n",
    "- Number of folds: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02720deb-9fa4-4d7e-ac6f-56e5841269cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best numTrees: 50\nBest maxDepth: 5\nTest RMSE = 48.2254, R2 = 0.5230\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. Hyperparameter grid for GBTRegressor\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.maxIter, [20, 50]) \\\n",
    "    .addGrid(regressor.maxDepth, [3, 5]) \\\n",
    "    .addGrid(regressor.stepSize, [0.1, 0.05]) \\\n",
    "    .build()\n",
    "\n",
    "# 9. Cross-validation setup\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5,\n",
    "    parallelism=2,\n",
    "    seed = 42 \n",
    ")\n",
    "\n",
    "# 10. Model fitting\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# 11. Best model & params\n",
    "best_model = cv_model.bestModel\n",
    "best_rf = best_model.stages[-1]\n",
    "print(f\"Best numTrees: {best_rf.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf.getOrDefault('maxDepth')}\")\n",
    "\n",
    "# 12. Test set evaluation\n",
    "preds = best_model.transform(test_df)\n",
    "rmse = evaluator.evaluate(preds)\n",
    "r2 = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\").evaluate(preds)\n",
    "print(f\"Test RMSE = {rmse:.4f}, R2 = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b9efd14-7375-4304-a26e-20c3698febf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Results: <br>\n",
    "- Best number of trees: 50\n",
    "- Best max depth: 5\n",
    "- Test RMSE: 48.2254\n",
    "- R2: 0.5230"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f1d3b18-14b1-4f8c-b2c8-89108ad03890",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next we have one of the three examples of pipeline setups using GBT Regressor that didn't finish running due to Databricks Community Edition limitations, after 1 hour of running the same code cell the cluster goes down and interrupts the run showing \"Cancelled\" as output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c582090a-a077-4381-b1d5-2553597fd38f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 8. Hyperparameter grid for GBTRegressor\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.maxIter, [20, 50]) \\\n",
    "    .addGrid(regressor.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(regressor.stepSize, [0.1, 0.05]) \\\n",
    "    .build()\n",
    "\n",
    "# 9. Cross-validation setup\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=2,\n",
    "    seed = 42 \n",
    ")\n",
    "\n",
    "# 10. Model fitting\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# 11. Best model & params\n",
    "best_model = cv_model.bestModel\n",
    "best_rf = best_model.stages[-1]\n",
    "print(f\"Best numTrees: {best_rf.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf.getOrDefault('maxDepth')}\")\n",
    "\n",
    "# 12. Test set evaluation\n",
    "preds = best_model.transform(test_df)\n",
    "rmse = evaluator.evaluate(preds)\n",
    "r2 = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\").evaluate(preds)\n",
    "print(f\"Test RMSE = {rmse:.4f}, R2 = {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb25f731-7250-41cb-91ca-b1158d5f5e24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A solution to turn around this problem would be to run this pipeline in smaller batches but we didn't wanted to loose information, therefore we opted not to have that approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0840f51-5120-4fbf-be88-5711fd664b73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32971303-3058-4770-8072-d3c66681ed65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next there is a table to access our different model setups to compare between them which one is the best one, therefore the one to be used for our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "012ae8d9-25b2-47d0-ab6e-03c1c5185591",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Setup                       | Model | Best Number of Trees | Best Max Depth                       | Test RMSE | R2 |\n",
    "|------------------------------|-------------|-------------|------------------------------|-------------|-------------|\n",
    "| First Run                 | Random Forest Regressor |50 |10                 | 49.3855 |0.4997                 |\n",
    "| Second Run                 |Random Forest Regressor | 100 |5                 | 52.4792 |0.4531                 |\n",
    "| Third Run                 | Random Forest Regressor |100 |10                 | 49.3130 |0.5012                 |\n",
    "| Fourth Run                 |Random Forest Regressor | 125 |15                 | 47.5310 |0.5366                 |\n",
    "| Fifth Run                 |GBT Regressor  |50 |5                 |48.2254  |0.5230                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5b690e4-86ea-468e-bf4d-843b8cb1a8cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "It is important to highlight once again that the metrics could be better if Databricks Community Edition allowed us to have longer runs in order to better optimize the models and have have better metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ddaa6a2-e193-4f52-990e-9e044e316eea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Conclusion:\n",
    "- With the Databricks Community Edition limitations our best model was a Random Forest Regressor with 125 trees, max depth of 15, test RMSE of 47.5310 and R2 of 0.5366."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_bda_group63_pipeline_NEW (1)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}