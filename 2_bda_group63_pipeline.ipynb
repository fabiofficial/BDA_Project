{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6dc024b-4c68-4042-ba30-bf116c67da14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Big Data Analytics Project - Airbnb Pricing Prediction <br>\n",
    "\n",
    "### Group 63 <br>\n",
    "André Lourenço - 20240743 <br>\n",
    "Fábio Dos Santos - 20240678 <br>\n",
    "Rafael Borges - 20240497 <br>\n",
    "Rui Reis - 20240854 <br>\n",
    "Victor Silva - 20240663 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e39b38c2-380b-416a-b533-2fda9d615c14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9021d181-9636-4741-9627-8dab513aa711",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, year, to_date, avg, regexp_replace, current_date, datediff, countDistinct, sum, round, when, lit\n",
    "from pyspark.sql import functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import (\n",
    "    VectorAssembler,\n",
    "    StringIndexer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    Imputer,\n",
    "    RobustScaler\n",
    ")\n",
    "from pyspark.ml.regression import RandomForestRegressor, LinearRegression, GBTRegressor\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.param.shared import Param\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.ml.param import Param # To get param names correctly\n",
    "\n",
    "# --- Configuration for Logging ---\n",
    "LOG_FILE_PATH = \"model_run_log_generic.csv\"\n",
    "LOG_HEADER = [\n",
    "    \"timestamp\",\n",
    "    \"run_type\",      # e.g., \"cv_trial\", \"final_test_evaluation\"\n",
    "    \"model_name\",    # Name of the estimator (e.g., RandomForestRegressor, LinearRegression)\n",
    "    \"params_json\",   # All hyperparameters for the trial as a JSON string\n",
    "    \"cv_metric_name\",\n",
    "    \"cv_metric_value\",\n",
    "    \"test_rmse\",\n",
    "    \"test_r2\",\n",
    "    \"notes\"\n",
    "]\n",
    "\n",
    "# Import json for serializing params\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2840519f-3ae5-43b5-bd3b-4695a75d6e3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def log_run_data(log_path, header, data_dict):\n",
    "    \"\"\"Appends a dictionary of data as a new row to a CSV file.\n",
    "    Creates the file with a header if it doesn't exist.\n",
    "    \"\"\"\n",
    "    file_exists = os.path.isfile(log_path)\n",
    "    try:\n",
    "        with open(log_path, 'a', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=header)\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "            # Ensure all header fields are present in data_dict, with None if missing\n",
    "            row_to_write = {h: data_dict.get(h) for h in header}\n",
    "            writer.writerow(row_to_write)\n",
    "    except IOError:\n",
    "        print(f\"IOError: Could not write to log file {log_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during logging: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddc40bc4-0bba-4e81-aaa1-6b9e03c22ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Project/utils\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20ef326a-05e1-4fba-9d59-3d2776c2a434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Project/transformers\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "694edebe-a0ce-42e8-a0fd-b0c6b00d2ebe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3229c279-06fb-4164-a3d0-0591805c6830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>host_is_superhost</th><th>host_total_listings_count</th><th>host_has_profile_pic</th><th>host_identity_verified</th><th>neighbourhood</th><th>property_type</th><th>room_type</th><th>accommodates</th><th>bedrooms</th><th>price</th><th>minimum_nights</th><th>review_scores_rating</th><th>instant_bookable</th><th>host_days_active</th><th>host_years_active</th><th>amenities_length</th><th>living_entertainment</th><th>kitchen_dining</th><th>bedroom</th><th>bathroom</th><th>baby_family</th><th>laundry_cleaning</th><th>safety_security</th><th>outdoor_garden</th><th>heating_cooling</th><th>travel_access</th><th>wellness_leisure</th><th>workspace_tech</th><th>guest_services</th><th>misc_essentials</th></tr></thead><tbody><tr><td>0</td><td>1</td><td>1</td><td>0</td><td>Buttes-Montmartre</td><td>Entire apartment</td><td>Entire place</td><td>2</td><td>1</td><td>53</td><td>2</td><td>100</td><td>0</td><td>3354</td><td>9</td><td>5</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td><td>1</td><td>Buttes-Montmartre</td><td>Entire apartment</td><td>Entire place</td><td>2</td><td>1</td><td>120</td><td>2</td><td>100</td><td>0</td><td>2627</td><td>7</td><td>8</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td></tr><tr><td>0</td><td>1</td><td>1</td><td>0</td><td>Elysee</td><td>Entire apartment</td><td>Entire place</td><td>2</td><td>1</td><td>89</td><td>2</td><td>100</td><td>0</td><td>2383</td><td>6</td><td>6</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td><td>1</td><td>Vaugirard</td><td>Entire apartment</td><td>Entire place</td><td>2</td><td>1</td><td>58</td><td>2</td><td>100</td><td>0</td><td>2609</td><td>7</td><td>5</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>0</td><td>1</td><td>1</td><td>0</td><td>Passy</td><td>Entire apartment</td><td>Entire place</td><td>2</td><td>1</td><td>60</td><td>2</td><td>100</td><td>0</td><td>2247</td><td>6</td><td>12</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>2</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         1,
         1,
         0,
         "Buttes-Montmartre",
         "Entire apartment",
         "Entire place",
         2,
         1,
         53,
         2,
         100,
         0,
         3354,
         9,
         5,
         0,
         1,
         0,
         0,
         0,
         1,
         0,
         0,
         1,
         1,
         0,
         1,
         0,
         0
        ],
        [
         0,
         1,
         1,
         1,
         "Buttes-Montmartre",
         "Entire apartment",
         "Entire place",
         2,
         1,
         120,
         2,
         100,
         0,
         2627,
         7,
         8,
         0,
         1,
         0,
         1,
         0,
         2,
         0,
         0,
         1,
         1,
         0,
         1,
         0,
         1
        ],
        [
         0,
         1,
         1,
         0,
         "Elysee",
         "Entire apartment",
         "Entire place",
         2,
         1,
         89,
         2,
         100,
         0,
         2383,
         6,
         6,
         1,
         1,
         0,
         0,
         0,
         1,
         0,
         0,
         1,
         1,
         0,
         1,
         0,
         0
        ],
        [
         0,
         1,
         1,
         1,
         "Vaugirard",
         "Entire apartment",
         "Entire place",
         2,
         1,
         58,
         2,
         100,
         0,
         2609,
         7,
         5,
         1,
         1,
         0,
         0,
         0,
         0,
         0,
         0,
         1,
         1,
         0,
         1,
         0,
         0
        ],
        [
         0,
         1,
         1,
         0,
         "Passy",
         "Entire apartment",
         "Entire place",
         2,
         1,
         60,
         2,
         100,
         0,
         2247,
         6,
         12,
         1,
         1,
         0,
         1,
         0,
         2,
         0,
         0,
         1,
         1,
         0,
         1,
         0,
         1
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "host_is_superhost",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "host_total_listings_count",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "host_has_profile_pic",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "host_identity_verified",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "neighbourhood",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "property_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "room_type",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "accommodates",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bedrooms",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "price",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "minimum_nights",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "review_scores_rating",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "instant_bookable",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "host_days_active",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "host_years_active",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "amenities_length",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "living_entertainment",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "kitchen_dining",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bedroom",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "bathroom",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "baby_family",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "laundry_cleaning",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "safety_security",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "outdoor_garden",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "heating_cooling",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "travel_access",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "wellness_leisure",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "workspace_tech",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "guest_services",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "misc_essentials",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = (\n",
    "    spark.read\n",
    "         .option(\"header\", \"true\")      # keep column names\n",
    "         .option(\"inferSchema\", \"true\") # let Spark inspect values & choose types\n",
    "         .option(\"samplingRatio\", \"1\")  # (optional) scan 100 % of the rows\n",
    "         .csv(\"dbfs:/FileStore/tables/Listings_cleaned\")\n",
    ")\n",
    "\n",
    "display(df.limit(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13c02d94-bc8a-433b-97d3-2eaf00952ce8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63750 rows × 30 columns\n"
     ]
    }
   ],
   "source": [
    "df_shape(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ef5f4f5-d672-44e7-bc3b-f79941fc9d47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# PIPELINE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eeb458d3-c481-4848-aae8-bd6a8bc421de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column                         |    # nulls | dtype\n---------------------------------------------------\nbedrooms                       |     13,293 | int\nreview_scores_rating           |     16,199 | int\n"
     ]
    }
   ],
   "source": [
    "summarize_nulls_and_dtype(df, only_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a04349f-71be-4d82-b4bb-6eb695f86487",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best numTrees: 50\nBest maxDepth: 5\nTest RMSE = 47.9895, R2 = 0.5303\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [\n",
    "    #'property_type', \n",
    "    'room_type', \n",
    "    'neighbourhood',\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    'host_total_listings_count',\n",
    "    'accommodates', \n",
    "    'bedrooms', \n",
    "    'minimum_nights', \n",
    "    'review_scores_rating', \n",
    "    'host_days_active',\n",
    "    'host_years_active',\n",
    "    'amenities_length', \n",
    "    \"living_entertainment\", \n",
    "    \"kitchen_dining\", \n",
    "    \"bedroom\", \n",
    "    \"bathroom\", \n",
    "    \"baby_family\", \n",
    "    \"laundry_cleaning\", \n",
    "    \"safety_security\", \n",
    "    \"outdoor_garden\", \n",
    "    \"heating_cooling\", \n",
    "    \"travel_access\", \n",
    "    \"wellness_leisure\", \n",
    "    \"workspace_tech\", \n",
    "    \"guest_services\", \n",
    "    \"misc_essentials\",\n",
    "]\n",
    "\n",
    "binary_cols = [\n",
    "    \"host_is_superhost\",\n",
    "    \"host_has_profile_pic\",\n",
    "    \"host_identity_verified\",\n",
    "    \"instant_bookable\"\n",
    "]\n",
    "\n",
    "label_col = \"price\"\n",
    "\n",
    "# 4. Train/test split\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 5. Build pipeline stages (applied per CV fold)\n",
    "stages = []\n",
    "\n",
    "# 5a. Categorical processing\n",
    "for cat in categorical_cols:\n",
    "    indexer = StringIndexer(inputCol=cat, outputCol=f\"{cat}_idx\")\n",
    "    ohe = OneHotEncoder(inputCol=f\"{cat}_idx\", outputCol=f\"{cat}_ohe\")\n",
    "    stages += [indexer, ohe]\n",
    "\n",
    "# 5b. Numeric imputation\n",
    "current_numeric_cols = list(numeric_cols) # Make a copy to modify\n",
    "processed_cols_map = {col: col for col in numeric_cols}\n",
    "\n",
    "\n",
    "imputer_input_actual = [\"review_scores_rating\", \"bedrooms\"] \n",
    "imputer_output_actual = [f\"{c}_imputed\" for c in imputer_input_actual]\n",
    "imputer = Imputer(inputCols=imputer_input_actual, outputCols=imputer_output_actual).setStrategy(\"median\")\n",
    "stages.append(imputer)\n",
    "\n",
    "# Update dict\n",
    "for orig_col, imputed_col in zip(imputer_input_actual, imputer_output_actual):\n",
    "    processed_cols_map[orig_col] = imputed_col\n",
    "\n",
    "# 5c. Winsorization\n",
    "\n",
    "winsor_input_original_names = [\"bedrooms\", \"minimum_nights\"] # Original names\n",
    "winsor_input_current_names = [processed_cols_map[c] for c in winsor_input_original_names]\n",
    "winsor_output = [f\"{processed_cols_map[c]}_wins\" for c in winsor_input_original_names]\n",
    "\n",
    "winsor = Winsorizer(\n",
    "    inputCols=winsor_input_current_names,\n",
    "    outputCols=winsor_output,\n",
    "    lowerQuantile=0.05,\n",
    "    upperQuantile=0.95\n",
    ")\n",
    "stages.append(winsor)\n",
    "\n",
    "\n",
    "# Update dict \n",
    "for orig_col, wins_col in zip(winsor_input_original_names, winsor_output):\n",
    "    processed_cols_map[orig_col] = wins_col\n",
    "\n",
    "final_numeric_features = list(processed_cols_map.values())\n",
    "\n",
    "# 5e. Assemble features\n",
    "onehot_cols  = [f\"{c}_ohe\" for c in categorical_cols]\n",
    "\n",
    "\n",
    "# Final feature input list\n",
    "feature_inputs = final_numeric_features + onehot_cols + binary_cols\n",
    "assembler = VectorAssembler(inputCols=feature_inputs, outputCol=\"assembled_features\")\n",
    "stages.append(assembler)\n",
    "\n",
    "# 5f. Feature scaling ( Unnecessary for tree based models )\n",
    "#scaler = RobustScaler(inputCol=\"assembled_features\", outputCol=\"features\")\n",
    "#stages.append(scaler)\n",
    "\n",
    "# 6. Estimator: RandomForestRegressor (or swap LinearRegression)\n",
    "# regressor = RandomForestRegressor(featuresCol=\"features\", labelCol=label_col, seed=42)\n",
    "\n",
    "regressor =  GBTRegressor(featuresCol=\"assembled_features\", labelCol=label_col, seed=42)\n",
    "stages.append(regressor)\n",
    "\n",
    "# 7. Pipeline creation\n",
    "pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# 8. Hyperparameter grid for Random Forest\n",
    "# paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(regressor.numTrees, [20, 50]) \\\n",
    "#     .addGrid(regressor.maxDepth, [5, 10]) \\\n",
    "#     .build()\n",
    "\n",
    "# 8. Hyperparameter grid for GBTRegressor\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(regressor.maxIter, [20, 50]) \\\n",
    "    .addGrid(regressor.maxDepth, [3, 5]) \\\n",
    "    .addGrid(regressor.stepSize, [0.1, 0.05]) \\\n",
    "    .build()\n",
    "\n",
    "# 9. Cross-validation setup\n",
    "evaluator = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5,\n",
    "    parallelism=2,\n",
    "    seed = 42 \n",
    ")\n",
    "\n",
    "# 10. Model fitting\n",
    "cv_model = crossval.fit(train_df)\n",
    "\n",
    "# 11. Best model & params\n",
    "best_model = cv_model.bestModel\n",
    "best_rf = best_model.stages[-1]\n",
    "print(f\"Best numTrees: {best_rf.getNumTrees}\")\n",
    "print(f\"Best maxDepth: {best_rf.getOrDefault('maxDepth')}\")\n",
    "\n",
    "# 12. Test set evaluation\n",
    "preds = best_model.transform(test_df)\n",
    "rmse = evaluator.evaluate(preds)\n",
    "r2 = RegressionEvaluator(labelCol=label_col, predictionCol=\"prediction\", metricName=\"r2\").evaluate(preds)\n",
    "print(f\"Test RMSE = {rmse:.4f}, R2 = {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_bda_group63_pipeline",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}