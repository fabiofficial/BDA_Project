{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "501985d4-3934-4ce4-bf0d-06c3c82959f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import sum, when, col, rand\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2f05967-1159-4082-8a82-706014df7dd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def df_shape(df):\n",
    "    # Rows\n",
    "    num_rows = df.count()\n",
    "\n",
    "    # Columns\n",
    "    num_cols = len(df.columns)\n",
    "\n",
    "    print(f\"{num_rows} rows × {num_cols} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea55c3cd-512c-4068-958e-eeeaad8b64f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_dist_and_box(\n",
    "    df,\n",
    "    cols,\n",
    "    bins,\n",
    "    hist_color: str = \"#5C666C\",\n",
    "    box_color: str = \"#BED62F\",\n",
    "):\n",
    "\n",
    "    # Accept a single string or any iterable of strings\n",
    "    if isinstance(cols, str):\n",
    "        cols = [cols]\n",
    "\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            print(f\"Column '{c}' not found – skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Pull only non-null rows for this column\n",
    "        pdf = df.select(c).where(col(c).isNotNull()).toPandas()\n",
    "\n",
    "        # Skip empty or non-numeric data\n",
    "        if pdf.empty or not pd.api.types.is_numeric_dtype(pdf[c]):\n",
    "            print(f\"Column '{c}' is empty or non-numeric – skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Create the two-row figure\n",
    "        fig, (ax_dist, ax_box) = plt.subplots(\n",
    "            2, 1, figsize=(8, 6), sharex=True, gridspec_kw={\"height_ratios\": [3, 1]}\n",
    "        )\n",
    "\n",
    "        # Histogram + KDE\n",
    "        sns.histplot(pdf[c], bins=bins, kde=True, color=hist_color, ax=ax_dist)\n",
    "        ax_dist.set_title(f\"Distribution of {c}\")\n",
    "        ax_dist.set_xlabel(\"\")  # Hide x-axis on the top panel\n",
    "        ax_dist.set_ylabel(\"Frequency\")\n",
    "\n",
    "        # Horizontal box-plot\n",
    "        sns.boxplot(x=pdf[c], orient=\"h\", color=box_color, ax=ax_box)\n",
    "        ax_box.set_xlabel(c)\n",
    "        ax_box.set_yticks([])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66456480-7749-43c9-a0f3-ad6c70122ad6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def summarize_nulls_and_dtype(df, only_missing=False):\n",
    "    \"\"\"\n",
    "    Print one line per column:\n",
    "        <column name> | <# nulls> | <Spark dtype>\n",
    "    If only_missing is True, only columns with at least one null are shown.\n",
    "    \"\"\"\n",
    "    # compute null counts for every column\n",
    "    counts_row = (\n",
    "        df\n",
    "        .select([ sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "                  for c in df.columns ])\n",
    "        .first()                     # a single Row with all counts\n",
    "        .asDict()\n",
    "    )\n",
    "\n",
    "    # header\n",
    "    header = f\"{'column':30} | {'# nulls':>10} | dtype\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "\n",
    "    # iterate through (name, dtype) pairs\n",
    "    for name, dtype in df.dtypes:\n",
    "        nulls = counts_row.get(name, 0)\n",
    "        # if only_missing, skip columns with zero nulls\n",
    "        if only_missing and nulls == 0:\n",
    "            continue\n",
    "        print(f\"{name:30} | {nulls:10,} | {dtype}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "285c1d53-a58f-4358-8a92-9f448a7beba6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def count_null_overlaps(df, cols):\n",
    "    \"\"\"\n",
    "    For a given DataFrame `df` and list of column names `cols`:\n",
    "      - Counts rows where all of `cols` are null.\n",
    "      - Counts rows where some but not all of `cols` are null.\n",
    "    Prints both counts.\n",
    "    \"\"\"\n",
    "\n",
    "    # build expressions\n",
    "    any_missing = reduce(lambda a, b: a | b,\n",
    "                         [col(c).isNull() for c in cols])\n",
    "    all_missing = reduce(lambda a, b: a & b,\n",
    "                         [col(c).isNull() for c in cols])\n",
    "\n",
    "    # perform counts\n",
    "    all_null_count = df.filter(all_missing).count()\n",
    "    partial_null_count = df.filter(any_missing & ~all_missing).count()\n",
    "\n",
    "    # output\n",
    "    print(f\"Rows with all {len(cols)} columns null at once: {all_null_count:,}\")\n",
    "    if partial_null_count == 0:\n",
    "        print(\"✅ No partial overlaps: whenever one is null, they’re all null together.\")\n",
    "    else:\n",
    "        print(f\"❌ Found {partial_null_count:,} rows with some nulls but not all.\")\n",
    "\n",
    "    # optionally, return the counts\n",
    "    return all_null_count, partial_null_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81802860-43de-4297-8a2f-2420028b7729",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def inspect_missing(df, column_name):\n",
    "    \"\"\"\n",
    "    Prints the percentage of missing values in `column_name` and\n",
    "    displays 10 random rows where that column is null.\n",
    "    \"\"\"\n",
    "    # Total rows\n",
    "    total_count = df.count()\n",
    "    \n",
    "    # Rows with null in the specified column\n",
    "    missing_df = df.filter(col(column_name).isNull())\n",
    "    missing_count = missing_df.count()\n",
    "    \n",
    "    # Compute percentage\n",
    "    missing_pct = (missing_count / total_count * 100) if total_count > 0 else 0.0\n",
    "    print(f\"{column_name}: {missing_count:,} missing out of {total_count:,} \"\n",
    "          f\"→ {missing_pct:.2f}% missing\")\n",
    "    \n",
    "    # Display 10 sample rows where column is null\n",
    "    random_nulls = missing_df.orderBy(rand()).limit(10)\n",
    "    print(f\"\\nShowing 10 random rows where `{column_name}` IS NULL:\")\n",
    "    display(random_nulls)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bcb9dd4a-4ccf-499d-8d2b-b4aa4d7d6ce5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_binary_with_target(df, binary_col, target_col):\n",
    "    \"\"\"\n",
    "    Given a DataFrame `df`, a binary column `binary_col` (0/1),\n",
    "    and a numeric target column `target_col`, this function:\n",
    "      1) Plots a horizontal bar chart of counts for each binary class.\n",
    "      2) Plots a boxplot of `target_col` grouped by `binary_col`.\n",
    "    \"\"\"\n",
    "    # 1) Aggregate counts by the binary column\n",
    "    status = (\n",
    "        df\n",
    "        .groupBy(binary_col)\n",
    "        .count()\n",
    "        .toPandas()\n",
    "    )\n",
    "    status = status.sort_values(by=binary_col)\n",
    "    status[binary_col] = status[binary_col].map({0: \"False\", 1: \"True\"})\n",
    "    status['count'] = status['count'].astype(int)\n",
    "    \n",
    "    # 2) Prepare data for the boxplot\n",
    "    box_pdf = (\n",
    "        df\n",
    "        .select(binary_col, target_col)\n",
    "        .na.drop()\n",
    "        .toPandas()\n",
    "    )\n",
    "    box_pdf[binary_col] = box_pdf[binary_col].map({0: \"False\", 1: \"True\"})\n",
    "    \n",
    "    # 3) Create subplots\n",
    "    fig, (ax_bar, ax_box) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # 4) Bar plot on ax_bar\n",
    "    sns.barplot(\n",
    "        data=status,\n",
    "        y=binary_col,\n",
    "        x=\"count\",\n",
    "        palette=main_palette,\n",
    "        ax=ax_bar\n",
    "    )\n",
    "    max_count = status['count'].max()\n",
    "    for p in ax_bar.patches:\n",
    "        ax_bar.text(\n",
    "            p.get_width() + max_count * 0.01,\n",
    "            p.get_y() + p.get_height() / 2,\n",
    "            int(p.get_width()),\n",
    "            va='center'\n",
    "        )\n",
    "    ax_bar.set_title(f\"Count of {binary_col} (False vs True)\", fontsize=14)\n",
    "    ax_bar.set_xlabel(\"Count\")\n",
    "    ax_bar.set_ylabel(binary_col)\n",
    "    \n",
    "    # 5) Boxplot on ax_box\n",
    "    sns.boxplot(\n",
    "        data=box_pdf,\n",
    "        x=binary_col,\n",
    "        y=target_col,\n",
    "        palette=main_palette,\n",
    "        ax=ax_box\n",
    "    )\n",
    "    ax_box.set_title(f\"{target_col} Distribution by {binary_col}\", fontsize=14)\n",
    "    ax_box.set_xlabel(binary_col)\n",
    "    ax_box.set_ylabel(target_col)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af0688f8-a234-4bc2-b08b-fc96160893ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_categorical_with_target(df, cat_col, target_col):\n",
    "    \"\"\"\n",
    "    Given a DataFrame `df`, a categorical column `cat_col`,\n",
    "    and a numeric target column `target_col`, this function:\n",
    "      1) Ignores rows where `cat_col` is null.\n",
    "      2) Plots a horizontal bar chart of counts for each category in `cat_col`.\n",
    "      3) Plots a boxplot of `target_col` grouped by `cat_col`.\n",
    "    \"\"\"\n",
    "    # 1) Filter out missing categorical values before aggregation\n",
    "    df_nonull = df.filter(col(cat_col).isNotNull())\n",
    "    \n",
    "    # 2) Aggregate counts by the categorical column\n",
    "    status = (\n",
    "        df_nonull\n",
    "        .groupBy(cat_col)\n",
    "        .count()\n",
    "        .toPandas()\n",
    "    )\n",
    "    status = status.sort_values(by=\"count\", ascending=False)\n",
    "    status['count'] = status['count'].astype(int)\n",
    "    \n",
    "    # 3) Prepare data for the boxplot (also drop nulls in target)\n",
    "    box_pdf = (\n",
    "        df_nonull\n",
    "        .filter(col(target_col).isNotNull())\n",
    "        .select(cat_col, target_col)\n",
    "        .toPandas()\n",
    "    )\n",
    "    \n",
    "    # 4) Create subplots\n",
    "    fig, (ax_bar, ax_box) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # 5) Bar plot on ax_bar\n",
    "    sns.barplot(\n",
    "        data=status,\n",
    "        y=cat_col,\n",
    "        x=\"count\",\n",
    "        palette=main_palette,\n",
    "        order=status[cat_col],  # ensure bars follow the sorted order\n",
    "        ax=ax_bar\n",
    "    )\n",
    "    max_count = status['count'].max()\n",
    "    for p in ax_bar.patches:\n",
    "        ax_bar.text(\n",
    "            p.get_width() + max_count * 0.01,\n",
    "            p.get_y() + p.get_height() / 2,\n",
    "            int(p.get_width()),\n",
    "            va='center'\n",
    "        )\n",
    "    ax_bar.set_title(f\"Count of categories in `{cat_col}`\", fontsize=14)\n",
    "    ax_bar.set_xlabel(\"Count\")\n",
    "    ax_bar.set_ylabel(cat_col)\n",
    "    \n",
    "    # 6) Boxplot on ax_box\n",
    "    sns.boxplot(\n",
    "        data=box_pdf,\n",
    "        x=cat_col,\n",
    "        y=target_col,\n",
    "        palette=main_palette,\n",
    "        order=status[cat_col],  # match the same order as bar chart\n",
    "        ax=ax_box\n",
    "    )\n",
    "    ax_box.set_title(f\"{target_col} Distribution by `{cat_col}`\", fontsize=14)\n",
    "    ax_box.set_xlabel(cat_col)\n",
    "    ax_box.set_ylabel(target_col)\n",
    "    ax_box.tick_params(axis='x', rotation=45)  # rotate x-labels if categories are long\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utils",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}